# Coursera-ML-by-Andrew-NG
Week 1: 
Don't have any exercises.

Week 2:
Programming exercise - Linear regression with single variable and multi variables. Gradient descent algorithm used to find optimum theta, Used normal equation to find optimal theta, changed alpha to see how cost fiunction varies over number of iterations

Week 3:
Logistic regression:
Programming exercise - Finding cost function, gradient, using fminunc, regularization, varying lambda to observe under fit and over fit.

Week 4:
Neural Networks:
